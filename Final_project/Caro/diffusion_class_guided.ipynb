{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OimlcBLxYkqc",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# This UNET-style prediction model was originally included as part of the Score-based generative modelling tutorial \n",
    "# by Yang Song et al: https://colab.research.google.com/drive/120kYYBOVa1i0TD85RjlEkFjaWDxSFUx3?usp=sharing\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class GaussianFourierProjection(nn.Module):\n",
    "  \"\"\"Gaussian random features for encoding time steps.\"\"\"  \n",
    "  def __init__(self, embed_dim, scale=30.):\n",
    "    super().__init__()\n",
    "    # Randomly sample weights during initialization. These weights are fixed \n",
    "    # during optimization and are not trainable.\n",
    "    self.W = nn.Parameter(torch.randn(embed_dim // 2) * scale, requires_grad=False)\n",
    "  def forward(self, x):\n",
    "    x_proj = x[:, None] * self.W[None, :] * 2 * np.pi\n",
    "    return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n",
    "\n",
    "\n",
    "class Dense(nn.Module):\n",
    "  \"\"\"A fully connected layer that reshapes outputs to feature maps.\"\"\"\n",
    "  def __init__(self, input_dim, output_dim):\n",
    "    super().__init__()\n",
    "    self.dense = nn.Linear(input_dim, output_dim)\n",
    "  def forward(self, x):\n",
    "    return self.dense(x)[..., None, None]\n",
    "\n",
    "\n",
    "class ScoreNet(nn.Module):\n",
    "  \"\"\"A time-dependent score-based model built upon U-Net architecture.\"\"\"\n",
    "\n",
    "  def __init__(self, marginal_prob_std, channels=[32, 64, 128, 256], embed_dim=256):\n",
    "    \"\"\"Initialize a time-dependent score-based network.\n",
    "\n",
    "    Args:\n",
    "      marginal_prob_std: A function that takes time t and gives the standard\n",
    "        deviation of the perturbation kernel p_{0t}(x(t) | x(0)).\n",
    "      channels: The number of channels for feature maps of each resolution.\n",
    "      embed_dim: The dimensionality of Gaussian random feature embeddings.\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    # Gaussian random feature embedding layer for time\n",
    "    self.embed = nn.Sequential(GaussianFourierProjection(embed_dim=embed_dim),\n",
    "         nn.Linear(embed_dim, embed_dim))\n",
    "    # Encoding layers where the resolution decreases\n",
    "    self.conv1 = nn.Conv2d(1, channels[0], 3, stride=1, bias=False)\n",
    "    self.dense1 = Dense(embed_dim, channels[0])\n",
    "    self.gnorm1 = nn.GroupNorm(4, num_channels=channels[0])\n",
    "    self.conv2 = nn.Conv2d(channels[0], channels[1], 3, stride=2, bias=False)\n",
    "    self.dense2 = Dense(embed_dim, channels[1])\n",
    "    self.gnorm2 = nn.GroupNorm(32, num_channels=channels[1])\n",
    "    self.conv3 = nn.Conv2d(channels[1], channels[2], 3, stride=2, bias=False)\n",
    "    self.dense3 = Dense(embed_dim, channels[2])\n",
    "    self.gnorm3 = nn.GroupNorm(32, num_channels=channels[2])\n",
    "    self.conv4 = nn.Conv2d(channels[2], channels[3], 3, stride=2, bias=False)\n",
    "    self.dense4 = Dense(embed_dim, channels[3])\n",
    "    self.gnorm4 = nn.GroupNorm(32, num_channels=channels[3])    \n",
    "\n",
    "    # Decoding layers where the resolution increases\n",
    "    self.tconv4 = nn.ConvTranspose2d(channels[3], channels[2], 3, stride=2, bias=False)\n",
    "    self.dense5 = Dense(embed_dim, channels[2])\n",
    "    self.tgnorm4 = nn.GroupNorm(32, num_channels=channels[2])\n",
    "    self.tconv3 = nn.ConvTranspose2d(channels[2] + channels[2], channels[1], 3, stride=2, bias=False, output_padding=1)    \n",
    "    self.dense6 = Dense(embed_dim, channels[1])\n",
    "    self.tgnorm3 = nn.GroupNorm(32, num_channels=channels[1])\n",
    "    self.tconv2 = nn.ConvTranspose2d(channels[1] + channels[1], channels[0], 3, stride=2, bias=False, output_padding=1)    \n",
    "    self.dense7 = Dense(embed_dim, channels[0])\n",
    "    self.tgnorm2 = nn.GroupNorm(32, num_channels=channels[0])\n",
    "    self.tconv1 = nn.ConvTranspose2d(channels[0] + channels[0], 1, 3, stride=1)\n",
    "    \n",
    "    # The swish activation function\n",
    "    self.act = lambda x: x * torch.sigmoid(x)\n",
    "    self.marginal_prob_std = marginal_prob_std\n",
    "  \n",
    "  def forward(self, x, t): \n",
    "    # Obtain the Gaussian random feature embedding for t   \n",
    "    embed = self.act(self.embed(t))    \n",
    "    # Encoding path\n",
    "    h1 = self.conv1(x)    \n",
    "    ## Incorporate information from t\n",
    "    h1 += self.dense1(embed)\n",
    "    ## Group normalization\n",
    "    h1 = self.gnorm1(h1)\n",
    "    h1 = self.act(h1)\n",
    "    h2 = self.conv2(h1)\n",
    "    h2 += self.dense2(embed)\n",
    "    h2 = self.gnorm2(h2)\n",
    "    h2 = self.act(h2)\n",
    "    h3 = self.conv3(h2)\n",
    "    h3 += self.dense3(embed)\n",
    "    h3 = self.gnorm3(h3)\n",
    "    h3 = self.act(h3)\n",
    "    h4 = self.conv4(h3)\n",
    "    h4 += self.dense4(embed)\n",
    "    h4 = self.gnorm4(h4)\n",
    "    h4 = self.act(h4)\n",
    "\n",
    "    # Decoding path\n",
    "    h = self.tconv4(h4)\n",
    "    ## Skip connection from the encoding path\n",
    "    h += self.dense5(embed)\n",
    "    h = self.tgnorm4(h)\n",
    "    h = self.act(h)\n",
    "    h = self.tconv3(torch.cat([h, h3], dim=1))\n",
    "    h += self.dense6(embed)\n",
    "    h = self.tgnorm3(h)\n",
    "    h = self.act(h)\n",
    "    h = self.tconv2(torch.cat([h, h2], dim=1))\n",
    "    h += self.dense7(embed)\n",
    "    h = self.tgnorm2(h)\n",
    "    h = self.act(h)\n",
    "    h = self.tconv1(torch.cat([h, h1], dim=1))\n",
    "\n",
    "    # Normalize output\n",
    "    h = h / self.marginal_prob_std(t)[:, None, None, None]\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ExponentialMovingAverage implementation as used in pytorch vision\n",
    "# https://github.com/pytorch/vision/blob/main/references/classification/utils.py#L159\n",
    "\n",
    "# BSD 3-Clause License\n",
    "\n",
    "# Copyright (c) Soumith Chintala 2016, \n",
    "# All rights reserved.\n",
    "\n",
    "# Redistribution and use in source and binary forms, with or without\n",
    "# modification, are permitted provided that the following conditions are met:\n",
    "\n",
    "# * Redistributions of source code must retain the above copyright notice, this\n",
    "#   list of conditions and the following disclaimer.\n",
    "\n",
    "# * Redistributions in binary form must reproduce the above copyright notice,\n",
    "#   this list of conditions and the following disclaimer in the documentation\n",
    "#   and/or other materials provided with the distribution.\n",
    "\n",
    "# * Neither the name of the copyright holder nor the names of its\n",
    "#   contributors may be used to endorse or promote products derived from\n",
    "#   this software without specific prior written permission.\n",
    "\n",
    "# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
    "# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
    "# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
    "# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
    "# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
    "# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
    "# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
    "# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
    "# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
    "# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
    "    \n",
    "class ExponentialMovingAverage(torch.optim.swa_utils.AveragedModel):\n",
    "    \"\"\"Maintains moving averages of model parameters using an exponential decay.\n",
    "    ``ema_avg = decay * avg_model_param + (1 - decay) * model_param``\n",
    "    `torch.optim.swa_utils.AveragedModel <https://pytorch.org/docs/stable/optim.html#custom-averaging-strategies>`_\n",
    "    is used to compute the EMA.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, decay, device=\"cpu\"):\n",
    "        def ema_avg(avg_model_param, model_param, num_averaged):\n",
    "            return decay * avg_model_param + (1 - decay) * model_param\n",
    "\n",
    "        super().__init__(model, device, ema_avg, use_buffers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "645d91e4bb974b1196be61b5077c9dc5",
      "78dc714c7aa347fb9fc41abf420222d9",
      "c1260f271df547fbb2a158ff6b3a3ff4",
      "e7313fdbb70442f4867644dfc85c3bcc",
      "a501588b5eb0494996dfb136565365ca",
      "89c68eded05d441daf94d145addb5ece",
      "2bffd3855f5744f588d5be1e5c4aed3e",
      "3b61ee9c62994863b718c086d4182f44",
      "8b905c5b2ad846ca837bd20cce2bf094",
      "b1416c32c4af4fe9a3c3fdcc5f33aca0",
      "aca161ff9f4b4a20b1457a8ee864f150"
     ]
    },
    "id": "mcoxR2ajYkqe",
    "outputId": "1f39bd8e-e78c-42e6-89cc-f1df34bdbdea"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms, utils\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "class DDPM(nn.Module):\n",
    "\n",
    "    def __init__(self, network, T=100, beta_1=1e-4, beta_T=2e-2):\n",
    "        \"\"\"\n",
    "        Initialize Denoising Diffusion Probabilistic Model\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        network: nn.Module\n",
    "            The inner neural network used by the diffusion process. Typically a Unet.\n",
    "        beta_1: float\n",
    "            beta_t value at t=1 \n",
    "        beta_T: [float]\n",
    "            beta_t value at t=T (last step)\n",
    "        T: int\n",
    "            The number of diffusion steps.\n",
    "        \"\"\"\n",
    "        \n",
    "        super(DDPM, self).__init__()\n",
    "\n",
    "        # Normalize time input before evaluating neural network\n",
    "        # Reshape input into image format and normalize time value before sending it to network model\n",
    "        self._network = network\n",
    "        self.network = lambda x, t: (self._network(x.reshape(-1, 1, 28, 28), \n",
    "                                                   (t.squeeze()/T))\n",
    "                                    ).reshape(-1, 28*28)\n",
    "\n",
    "        # Total number of time steps\n",
    "        self.T = T\n",
    "\n",
    "\n",
    "        # Registering as buffers to ensure they get transferred to the GPU automatically\n",
    "        self.register_buffer(\"beta\", torch.linspace(beta_1, beta_T, T+1))\n",
    "        self.register_buffer(\"alpha\", 1-self.beta)\n",
    "        self.register_buffer(\"alpha_bar\", self.alpha.cumprod(dim=0))\n",
    "        \n",
    "\n",
    "    def forward_diffusion(self, x0, t, epsilon):\n",
    "        '''\n",
    "        q(x_t | x_0)\n",
    "        Forward diffusion from an input datapoint x0 to an xt at timestep t, provided a N(0,1) noise sample epsilon. \n",
    "        Note that we can do this operation in a single step\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x0: torch.tensor\n",
    "            x value at t=0 (an input image)\n",
    "        t: int\n",
    "            step index \n",
    "        epsilon:\n",
    "            noise sample\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.tensor\n",
    "            image at timestep t\n",
    "        ''' \n",
    "\n",
    "        mean = torch.sqrt(self.alpha_bar[t])*x0\n",
    "        std = torch.sqrt(1 - self.alpha_bar[t])\n",
    "        \n",
    "        return mean + std*epsilon\n",
    "\n",
    "    def reverse_diffusion(self, xt, t, epsilon):\n",
    "        \"\"\"\n",
    "        p(x_{t-1} | x_t)\n",
    "        Single step in the reverse direction, from x_t (at timestep t) to x_{t-1}, provided a N(0,1) noise sample epsilon.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        xt: torch.tensor\n",
    "            x value at step t\n",
    "        t: int\n",
    "            step index\n",
    "        epsilon:\n",
    "            noise sample\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.tensor\n",
    "            image at timestep t-1\n",
    "        \"\"\"\n",
    "\n",
    "        mean =  1./torch.sqrt(self.alpha[t]) * (xt - (self.beta[t])/torch.sqrt(1-self.alpha_bar[t])*self.network(xt, t)) \n",
    "        std = torch.where(t>0, torch.sqrt(((1-self.alpha_bar[t-1]) / (1-self.alpha_bar[t]))*self.beta[t]), 0)\n",
    "        \n",
    "        return mean + std*epsilon\n",
    "    \n",
    "\n",
    "    # The next two functions are added for the classifier guided sampling\n",
    "\n",
    "    def get_gradients_classifier(self,classifier, x_t, t, y):\n",
    "        \"\"\"\n",
    "        Get gradients of the classifier model with respect to the input x_t\n",
    "        for a specific class y\n",
    "        \"\"\"\n",
    "        with torch.enable_grad():\n",
    "            x_t = x_t.clone().detach().requires_grad_(True)  # shape: nsamples, 28x28\n",
    "            #shape of t: nsamples, 1\n",
    "\n",
    "            #the shape of output is the problem, should be nsamples, 10\n",
    "            t1= t[0]\n",
    "            output = classifier(x_t, t1)  # shape: nsamples, nsamples, 10\n",
    "\n",
    "            scalar_value =torch.mean(output[:, y])# This scalar value represents the total contribution of class y across all instances in the batch.\n",
    "\n",
    "            grads = torch.autograd.grad(scalar_value, x_t)[0] #shape: same as x_t\n",
    "\n",
    "        return grads\n",
    "\n",
    "\n",
    "    def reverse_diffusion_guided(self,classifier, xt, t, y, weight, epsilon):\n",
    "        grads = self.get_gradients_classifier(classifier, xt, t, y) # get gradients, but dimension 28x28 \n",
    "        mean =  1./torch.sqrt(self.alpha[t]) * (xt - (self.beta[t])/torch.sqrt(1-self.alpha_bar[t])*self.network(xt, t)) \n",
    "        std = torch.where(t>0, torch.sqrt(((1-self.alpha_bar[t-1]) / (1-self.alpha_bar[t]))*self.beta[t]), 0)\n",
    "        mean_guided = mean + weight * std**2 * grads\n",
    "\n",
    "        return mean_guided + std*epsilon\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def sample(self, shape, weight = 0 ,y=None, classifier = None):\n",
    "        \"\"\"\n",
    "        Sample from diffusion model (Algorithm 2 in Ho et al, 2020)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        shape: tuple\n",
    "            Specify shape of sampled output. For MNIST: (nsamples, 28*28)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.tensor\n",
    "            sampled image            \n",
    "        \"\"\"\n",
    "        \n",
    "        # Sample xT: Gaussian noise\n",
    "        xT = torch.randn(shape).to(self.beta.device)\n",
    "\n",
    "        xt = xT\n",
    "\n",
    "        if weight == 0:\n",
    "            for t in range(self.T, 0, -1):\n",
    "                noise = torch.randn_like(xT) if t > 1 else 0\n",
    "                t = torch.tensor(t).expand(xt.shape[0], 1).to(self.beta.device)            \n",
    "                xt = self.reverse_diffusion(xt, t, noise)\n",
    "\n",
    "\n",
    "        # This part is added for the classifier guided sampling\n",
    "        # If weight is not 0, then we are doing the guided sampling are calling the reverse_diffusion_guided function\n",
    "        else:\n",
    "            for t in range(self.T, 0, -1):\n",
    "                noise = torch.randn_like(xT) if t > 1 else 0\n",
    "                t = torch.tensor(t).expand(xt.shape[0], 1).to(self.beta.device)\n",
    "                \n",
    "                #with torch.enable_grad():\n",
    "                xt = self.reverse_diffusion_guided(classifier, xt, t, y, weight, noise)\n",
    "\n",
    "        return xt\n",
    "\n",
    "    \n",
    "    def elbo_simple(self, x0):\n",
    "        \"\"\"\n",
    "        ELBO training objective (Algorithm 1 in Ho et al, 2020)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x0: torch.tensor\n",
    "            Input image\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            ELBO value            \n",
    "        \"\"\"\n",
    "\n",
    "        # Sample time step t\n",
    "        t = torch.randint(1, self.T, (x0.shape[0],1)).to(x0.device)\n",
    "        \n",
    "        # Sample noise\n",
    "        epsilon = torch.randn_like(x0)\n",
    "\n",
    "        # TODO: Forward diffusion to produce image at step t\n",
    "        xt = self.forward_diffusion(x0, t, epsilon)\n",
    "        \n",
    "        return -nn.MSELoss(reduction='mean')(epsilon, self.network(xt, t))\n",
    "\n",
    "    \n",
    "    def loss(self, x0):\n",
    "        \"\"\"\n",
    "        Loss function. Just the negative of the ELBO.\n",
    "        \"\"\"\n",
    "        return -self.elbo_simple(x0).mean()\n",
    "\n",
    "\n",
    "def train(model, optimizer, scheduler, dataloader, epochs, device, ema=True, per_epoch_callback=None):\n",
    "    \"\"\"\n",
    "    Training loop\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: nn.Module\n",
    "        Pytorch model\n",
    "    optimizer: optim.Optimizer\n",
    "        Pytorch optimizer to be used for training\n",
    "    scheduler: optim.LRScheduler\n",
    "        Pytorch learning rate scheduler\n",
    "    dataloader: utils.DataLoader\n",
    "        Pytorch dataloader\n",
    "    epochs: int\n",
    "        Number of epochs to train\n",
    "    device: torch.device\n",
    "        Pytorch device specification\n",
    "    ema: Boolean\n",
    "        Whether to activate Exponential Model Averaging\n",
    "    per_epoch_callback: function\n",
    "        Called at the end of every epoch\n",
    "    \"\"\"\n",
    "\n",
    "    # Setup progress bar\n",
    "    total_steps = len(dataloader)*epochs\n",
    "    progress_bar = tqdm(range(total_steps), desc=\"Training\")\n",
    "\n",
    "    if ema:\n",
    "        ema_global_step_counter = 0\n",
    "        ema_steps = 10\n",
    "        ema_adjust = dataloader.batch_size * ema_steps / epochs\n",
    "        ema_decay = 1.0 - 0.995\n",
    "        ema_alpha = min(1.0, (1.0 - ema_decay) * ema_adjust)\n",
    "        ema_model = ExponentialMovingAverage(model, device=device, decay=1.0 - ema_alpha)                \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # Switch to train mode\n",
    "        model.train()\n",
    "\n",
    "        global_step_counter = 0\n",
    "        for i, (x, _) in enumerate(dataloader):\n",
    "            x = x.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = model.loss(x)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix(loss=f\"⠀{loss.item():12.4f}\", epoch=f\"{epoch+1}/{epochs}\", lr=f\"{scheduler.get_last_lr()[0]:.2E}\")\n",
    "            progress_bar.update()\n",
    "\n",
    "            if ema:\n",
    "                ema_global_step_counter += 1\n",
    "                if ema_global_step_counter%ema_steps==0:\n",
    "                    ema_model.update_parameters(model)                \n",
    "        \n",
    "        if per_epoch_callback:\n",
    "            per_epoch_callback(ema_model.module if ema else model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parameters\n",
    "T = 1000\n",
    "learning_rate = 1e-3\n",
    "epochs = 50\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "# Rather than treating MNIST images as discrete objects, as done in Ho et al 2020, \n",
    "# we here treat them as continuous input data, by dequantizing the pixel values (adding noise to the input data)\n",
    "# Also note that we map the 0..255 pixel values to [-1, 1], and that we process the 28x28 pixel values as a flattened 784 tensor.\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Lambda(lambda x: x + torch.rand(x.shape)/255),    # Dequantize pixel values\n",
    "    transforms.Lambda(lambda x: (x-0.5)*2.0),                    # Map from [0,1] -> [-1, -1]\n",
    "    transforms.Lambda(lambda x: x.flatten())\n",
    "])\n",
    "\n",
    "# Download and transform train dataset\n",
    "dataloader_train = torch.utils.data.DataLoader(datasets.MNIST('./mnist_data', download=True, train=True, transform=transform),\n",
    "                                                batch_size=batch_size,\n",
    "                                                shuffle=True)\n",
    "\n",
    "# Select device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Construct Unet\n",
    "# The original ScoreNet expects a function with std for all the\n",
    "# different noise levels, such that the output can be rescaled.\n",
    "# Since we are predicting the noise (rather than the score), we\n",
    "# ignore this rescaling and just set std=1 for all t.\n",
    "mnist_unet = ScoreNet((lambda t: torch.ones(1).to(device)))\n",
    "\n",
    "# Construct model\n",
    "model = DDPM(mnist_unet, T=T).to(device)\n",
    "\n",
    "# Construct optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Setup simple scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.9999)\n",
    "\n",
    "\n",
    "def reporter(model):\n",
    "    \"\"\"Callback function used for plotting images during training\"\"\"\n",
    "    \n",
    "    # Switch to eval mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        nsamples = 10\n",
    "        samples = model.sample((nsamples,28*28)).to(device)\n",
    "        \n",
    "        # Map pixel values back from [-1,1] to [0,1]\n",
    "        samples = (samples+1)/2 \n",
    "        samples = samples.clamp(0.0, 1.0)\n",
    "\n",
    "        # Plot in grid\n",
    "        grid = utils.make_grid(samples.reshape(-1, 1, 28, 28), nrow=nsamples)\n",
    "        plt.gca().set_axis_off()\n",
    "        plt.imshow(transforms.functional.to_pil_image(grid), cmap=\"gray\")\n",
    "        plt.show()    \n",
    "\n",
    "# Call training loop\n",
    "train(model, optimizer, scheduler, dataloader_train, \n",
    "      epochs=epochs, device=device, ema=True, per_epoch_callback=reporter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Classifier\n",
    "\n",
    "Training a classifier $f_\\theta(y|x_t,t)$ on noisy data $x_t, t$ from the forward diffusion process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, embed_dim=128):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.embed = nn.Sequential(GaussianFourierProjection(embed_dim=embed_dim),\n",
    "         nn.Linear(embed_dim, embed_dim))\n",
    "        self.fc1 = nn.Linear(28*28, 128)  # Input layer (28x28 pixels flattened)\n",
    "        self.fc2 = nn.Linear(128, 64)    # Hidden layer\n",
    "        self.fc3 = nn.Linear(64, 10)     # Output layer (10 classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.act = lambda x: x * torch.sigmoid(x)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        t_embedding = self.act(self.embed(t))\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.relu(self.fc1(x)+ t_embedding)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "def get_noisy_datasets(diff_model, batch_size=64, device=device):\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Lambda(lambda x: x + torch.rand(x.shape)/255),    # Dequantize pixel values\n",
    "        transforms.Lambda(lambda x: (x-0.5)*2.0),                    # Map from [0,1] -> [-1, -1]\n",
    "        transforms.Lambda(lambda x: x.flatten())\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "    test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "    train_dataset.data = train_dataset.data.to(device)\n",
    "    train_dataset.targets = train_dataset.targets.to(device)\n",
    "    test_dataset.data = test_dataset.data.to(device)\n",
    "    test_dataset.targets = test_dataset.targets.to(device)\n",
    "\n",
    "    #iterate over samples in the training dataset\n",
    "    x_train = train_dataset.data.float()\n",
    "    y_train = train_dataset.targets\n",
    "\n",
    "    x_test = test_dataset.data.float()\n",
    "    y_test = test_dataset.targets\n",
    "\n",
    "    y_t = [y_train]\n",
    "    timestep = [torch.zeros_like(y_train)]\n",
    "\n",
    "    y_t_test = [y_test]\n",
    "    timestep_test = [torch.zeros_like(y_test)]\n",
    "\n",
    "    # train dataset\n",
    "    t = torch.randint(low=1, high=T+1, size=[x_train.shape[0]], device=device)\n",
    "    epsilon = torch.randn_like(x_train, device=device)\n",
    "\n",
    "    noisy=[]\n",
    "    for i in range(len(t)):\n",
    "        noisy.append(diff_model.forward_diffusion(x_train[i], t[i], epsilon[i]))\n",
    "        \n",
    "    noisy = torch.stack(noisy, dim=0)\n",
    "    x_t=torch.concat((x_train, noisy), dim=0)\n",
    "\n",
    "    y_t.append(y_train)\n",
    "    y_t = torch.cat(y_t, dim=0)\n",
    "    timestep.append(t)\n",
    "    timestep = torch.cat(timestep, dim=0).squeeze()\n",
    "\n",
    "    train_dataset_noisy = torch.utils.data.TensorDataset(x_t.unsqueeze(1), y_t, timestep)\n",
    "    train_loader_noisy = torch.utils.data.DataLoader(train_dataset_noisy, batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "    # test dataset\n",
    "    t_test = torch.randint(low=1, high=T+1, size=[x_test.shape[0]], device=device)\n",
    "    epsilon_test = torch.randn_like(x_test, device=device)\n",
    "\n",
    "    noisy_test=[]\n",
    "    for i in range(len(t_test)):\n",
    "        noisy_test.append(diff_model.forward_diffusion(x_test[i], t_test[i], epsilon_test[i]))\n",
    "        \n",
    "    noisy_test = torch.stack(noisy_test, dim=0)\n",
    "    x_t_test=torch.concat((x_test, noisy_test), dim=0)\n",
    "\n",
    "    y_t_test.append(y_test)\n",
    "    y_t_test = torch.cat(y_t_test, dim=0)\n",
    "\n",
    "    timestep_test.append(t_test)\n",
    "    timestep_test = torch.cat(timestep_test, dim=0).squeeze()  \n",
    "\n",
    "    test_dataset_noisy = torch.utils.data.TensorDataset(x_t_test.unsqueeze(1), y_t_test, timestep_test)\n",
    "    test_loader_noisy = torch.utils.data.DataLoader(test_dataset_noisy, batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader_noisy, test_loader_noisy\n",
    "\n",
    "def train_classifier(train_loader, test_loader, learning_rate, batch_size,epochs, device):\n",
    "    model = Classifier().to(device)\n",
    "\n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train the model\n",
    "    train_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for images, labels, t in train_loader:\n",
    "            images, labels, t = images.to(device), labels.to(device), t.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images, t)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        train_losses.append(epoch_loss / len(train_loader))\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, t  in test_loader:\n",
    "            images, labels, t = images.to(device), labels.to(device), t.to(device)\n",
    "            outputs = model(images, t)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "    # Plot training loss\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train classifier\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_loader_noisy, test_loader_noisy \u001b[38;5;241m=\u001b[39m \u001b[43mget_noisy_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDDPM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmnist_unet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m classifier \u001b[38;5;241m=\u001b[39m train_classifier(train_loader_noisy, test_loader_noisy, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "Cell \u001b[0;32mIn[9], line 58\u001b[0m, in \u001b[0;36mget_noisy_datasets\u001b[0;34m(diff_model, batch_size, device)\u001b[0m\n\u001b[1;32m     56\u001b[0m noisy\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(t)):\n\u001b[0;32m---> 58\u001b[0m     noisy\u001b[38;5;241m.\u001b[39mappend(\u001b[43mdiff_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_diffusion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     60\u001b[0m noisy \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(noisy, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     61\u001b[0m x_t\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mconcat((x_train, noisy), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 64\u001b[0m, in \u001b[0;36mDDPM.forward_diffusion\u001b[0;34m(self, x0, t, epsilon)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_diffusion\u001b[39m(\u001b[38;5;28mself\u001b[39m, x0, t, epsilon):\n\u001b[1;32m     44\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03m    q(x_t | x_0)\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m    Forward diffusion from an input datapoint x0 to an xt at timestep t, provided a N(0,1) noise sample epsilon. \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m        image at timestep t\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m \n\u001b[0;32m---> 64\u001b[0m     mean \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha_bar\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m)\u001b[38;5;241m*\u001b[39mx0\n\u001b[1;32m     65\u001b[0m     std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha_bar[t])\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mean \u001b[38;5;241m+\u001b[39m std\u001b[38;5;241m*\u001b[39mepsilon\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train classifier\n",
    "train_loader_noisy, test_loader_noisy = get_noisy_datasets(DDPM(mnist_unet, T=1000).to(device), batch_size=64, device=device)\n",
    "classifier = train_classifier(train_loader_noisy, test_loader_noisy, learning_rate=1e-3, epochs=50, batch_size=64, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/16/r76sng_n05zfpw9mshyz8xbc0000gn/T/ipykernel_10804/1589775987.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load('model_50epochs.pth')\n",
      "/var/folders/16/r76sng_n05zfpw9mshyz8xbc0000gn/T/ipykernel_10804/1589775987.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load('classifier_50epochs.pth')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (embed): Sequential(\n",
       "    (0): GaussianFourierProjection()\n",
       "    (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = DDPM(mnist_unet, T=T).to(device)\n",
    "\n",
    "# Load the state dictionary\n",
    "state_dict = torch.load('model_50epochs.pth')\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# Use the model\n",
    "model.eval() \n",
    "\n",
    "# Instantiate the classifier\n",
    "classifier = Classifier().to(device)\n",
    "\n",
    "# Load the state dictionary\n",
    "state_dict = torch.load('classifier_50epochs.pth')\n",
    "classifier.load_state_dict(state_dict)\n",
    "\n",
    "# Use the classifier\n",
    "classifier.eval() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Classifier Guided Samples\n",
    "\n",
    "Calling the samples function from the diffusion process with a non-zero weight $w=10$ and value $y=4$ to guide the diffusion process to sample 10 MNIST pictures of fours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0688, -1.7534, -1.1228, -0.0732, -1.2273, -0.3734, -2.2844, -1.3090,\n",
      "          1.2880, -0.1893],\n",
      "        [-0.9155, -1.3873, -0.4899,  0.1180, -1.4122, -0.2269, -1.4016, -1.3312,\n",
      "          1.4772, -0.4181],\n",
      "        [-0.9868, -1.4458, -0.4845,  0.0928, -1.5260, -0.2288, -1.4181, -1.4346,\n",
      "          1.5526, -0.5319],\n",
      "        [-0.7384, -1.1837, -0.3468,  0.2138, -1.2336, -0.1876, -1.1550, -1.1336,\n",
      "          1.3750, -0.2502],\n",
      "        [-1.2916, -2.1557, -1.6947, -0.2770, -1.1907, -0.5094, -3.1099, -1.4089,\n",
      "          1.2028, -0.1126],\n",
      "        [-0.8559, -1.3648, -0.5654,  0.1240, -1.2696, -0.2410, -1.4812, -1.2177,\n",
      "          1.3753, -0.2707],\n",
      "        [-1.2054, -1.8284, -1.2989, -0.2573, -1.0898, -0.5558, -2.5296, -1.2805,\n",
      "          1.1842, -0.0765],\n",
      "        [-1.1317, -1.6444, -0.6874, -0.0039, -1.6148, -0.2799, -1.7328, -1.5636,\n",
      "          1.5894, -0.6061],\n",
      "        [-0.8339, -1.4211, -0.7842,  0.0795, -1.0752, -0.2971, -1.7597, -1.0936,\n",
      "          1.2244, -0.0638],\n",
      "        [-1.0243, -1.4854, -0.5053,  0.0745, -1.5702, -0.2350, -1.4578, -1.4800,\n",
      "          1.5795, -0.5744]], device='mps:0', grad_fn=<LinearBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "nsamples = 10\n",
    "\n",
    "w=7\n",
    "y=4\n",
    "\n",
    "# Sample from the model using classifier guidance if weight is non-zero\n",
    "samples = model.sample((nsamples,28*28), w, y, classifier = classifier).to(device)\n",
    "\n",
    "# Map pixel values back from [-1,1] to [0,1]\n",
    "samples = (samples+1)/2 \n",
    "samples = samples.clamp(0.0, 1.0)\n",
    "\n",
    "# Plot in grid\n",
    "grid = utils.make_grid(samples[:10].reshape(-1, 1, 28, 28), nrow=nsamples)\n",
    "plt.gca().set_axis_off()\n",
    "plt.imshow(transforms.functional.to_pil_image(grid), cmap=\"gray\")\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(f'guided_sampling_y{y}_w{w}.png')\n",
    "\n",
    "plt.show()    \n",
    "# Test if the classifier would correctly classify the generated samples\n",
    "\n",
    "# note that the prediction would be the maximum of the output of the classifier\n",
    "print(classifier(samples, torch.tensor([0]).to(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from torchmetrics.image.inception import InceptionScore\n",
    " \n",
    "def calculate_inception_score_and_fid(\n",
    "    generated_samples,\n",
    "    real_samples,\n",
    "    batch_size=32,\n",
    "    device=None,\n",
    "    resize=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates Inception Score (IS) and Fréchet Inception Distance (FID) for generated samples.\n",
    " \n",
    "    Args:\n",
    "        generated_samples (torch.Tensor): Generated images, shape (N, 3, H, W), values in [0, 1].\n",
    "        real_samples (torch.Tensor): Real images for FID comparison, shape (N, 3, H, W), values in [0, 1].\n",
    "        batch_size (int): Batch size for processing images.\n",
    "        device (torch.device): Device to run computations on. If None, uses CUDA if available.\n",
    "        resize (bool): Whether to resize images to 299x299 required by InceptionV3.\n",
    " \n",
    "    Returns:\n",
    "        is_mean (float): The Inception Score mean.\n",
    "        is_std (float): The Inception Score standard deviation.\n",
    "        fid_score (float): The Fréchet Inception Distance.\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    " \n",
    "    # Define image transformations\n",
    "    transform = transforms.Resize((299, 299)) if resize else nn.Identity()\n",
    " \n",
    "    # Initialize metrics\n",
    "    fid = FrechetInceptionDistance(feature=2048).to(device)\n",
    "    is_metric = InceptionScore().to(device)\n",
    "    # Function to preprocess and convert images\n",
    "    def preprocess(batch):\n",
    "        # Resize if necessary\n",
    "        if resize:\n",
    "            batch = nn.functional.interpolate(batch, size=(299, 299), mode='bilinear', align_corners=False)\n",
    "        # Scale to [0, 255] and convert to uint8\n",
    "        batch = (batch * 255).clamp(0, 255).to(torch.uint8)\n",
    "        return batch\n",
    " \n",
    "    # Process generated samples for IS and FID\n",
    "    for i in range(0, generated_samples.size(0), batch_size):\n",
    "        batch = generated_samples[i:i + batch_size]\n",
    "        batch = preprocess(batch).to(device)\n",
    "        fid.update(batch, real=False)\n",
    "        is_metric.update(batch)\n",
    " \n",
    "    # Process real samples for FID\n",
    "    for i in range(0, real_samples.size(0), batch_size):\n",
    "        batch = real_samples[i:i + batch_size]\n",
    "        batch = preprocess(batch).to(device)\n",
    "        fid.update(batch, real=True)\n",
    " \n",
    "    # Compute scores\n",
    "    fid_score = fid.compute().item()\n",
    "    is_mean, is_std = is_metric.compute()\n",
    " \n",
    "    return is_mean, is_std, fid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `InceptionScore` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    }
   ],
   "source": [
    "real_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "real_dataset.data = real_dataset.data.to(device).float()\n",
    "real_dataset.targets = real_dataset.targets.to(device)\n",
    "real_x = real_dataset.data\n",
    "real_y = real_dataset.targets\n",
    "\n",
    "# get samples of fours\n",
    "real_fours = real_x[real_y == 4]\n",
    "real_fours = real_fours[:10]\n",
    "\n",
    "# Plot in grid\n",
    "grid = utils.make_grid(real_fours.reshape(-1, 1, 28, 28), nrow=nsamples)\n",
    "plt.gca().set_axis_off()\n",
    "plt.imshow(transforms.functional.to_pil_image(grid), cmap=\"gray\")\n",
    "plt.show()    \n",
    "\n",
    "samples_fmt, real_fmt = samples.reshape(-1, 1, 28, 28), real_fours.reshape(-1, 1, 28, 28)\n",
    "\n",
    "#torch cat x3 along dim 1 for each (RGB implementation)\n",
    "samples_fmt = torch.cat([samples_fmt, samples_fmt, samples_fmt], dim=1).type(dtype=torch.uint8)\n",
    "real_fmt = torch.cat([real_fmt, real_fmt, real_fmt], dim=1).type(dtype=torch.uint8)\n",
    "\n",
    "is_mean, is_std, fid_score = calculate_inception_score_and_fid(samples_fmt, real_fmt, batch_size=32, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.) tensor(5.9605e-08) 357.9425354003906\n"
     ]
    }
   ],
   "source": [
    "print(is_mean, is_std, fid_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional stuff I used for testing\n",
    "\n",
    "I.e. testing out the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##test for classifier by giving it unnoised MNIST\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_dataset.data = train_dataset.data.to(device)\n",
    "x_train = train_dataset.data.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAJdUlEQVR4nO3cMYjX9R/H8c/XBLWzgiYHQ1C0JiFvCVKUawgkSIQTQ2myTWgQFx2CliC4pYYaanE56CAOtwYHQbAhvBoaGhqSIFJRUVPC7Nvwhxd/+PcH3x/0d6f3eOwvPl+806ef5TOM4zg2AGitrVnuDwBg5RAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgFi73B8AT7Lp6eny5vjx411nvfvuu+XNmTNnyptPP/20vLl06VJ5w8rkpgBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQwziO43J/BKwEt27dKm82btz4GL7k303qr+owDOXNmjX+f/m08JMEIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQAiLXL/QHwOLz22mvlzcLCQnkzNTVV3vQ+bHf79u3y5q+//ipvXnzxxfLm9ddfL29++umn8qa11q5du9a14+G4KQAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgDEMPa+zgVFzz33XNfu1VdfLW/OnDlT3mzevLm8GYahvOn9K7e0tFTe3Lt3r7zZvXt3edPz5/Drr7+WN6219tJLL3XteDhuCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgDE2uX+AFaPzz77rGt3+PDhR/wlT6ae12KPHTtW3ty/f7+82bdvX3lz4cKF8qa11t55552uHQ/HTQGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgPIhHl4WFhfJm//79XWcNw9C1m4STJ0+WN3Nzc11n3bx5s7xZWloqb27cuFHezMzMlDcr+ee6mrkpABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAMQwjuO43B/B8vrjjz/Km6mpqfLmwYMH5U1rrfX8iv7+++/lzcsvv1ze7N27t7zZuXNnedNaa1988UV5c/Xq1a6zqnp+tnfv3u06q+fP/NKlS11nrUZuCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgCxdrk/gEdrx44d5c0HH3xQ3hw+fLi86X0A7eeffy5vFhcXy5s7d+6UN5P00UcfLfcnPFIbNmzo2p04ceIRfwn/zU0BgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBjGcRyX+yP4X+vWrevaLSwslDf79+8vb3peFF2/fn1501rfi6xLS0vlzS+//FLe8B8PHjwob3r/6bl48WJ5s2fPnq6zViM3BQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYBYu9wfwL/btWtX167ncbseb7/9dnlz/vz5rrMWFxe7dkCdmwIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAeBBvhZqbm+vaDcNQ3vQ8VNf7uB1PpzVr6v+//Pvvv7vO6vkd5+G5KQAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEB/Em4K233ipvvvrqq66zxnEsb86ePVvezMzMlDc8vXoet+v5XW2tte+//7682b17d9dZq5GbAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAEAMY++rVDy02dnZ8mZ+fr7rrCtXrpQ309PT5c1vv/1W3jB5zz77bHnz5ZdfljeHDh0qb86dO1fetNbawYMHy5s7d+50nbUauSkAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEGuX+wN4tP7888/yxounT4bnn3++vDl16lR50/Oq7/3798ububm58qY1L54+bm4KAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCAOFBvKfM2bNny5v333//MXwJ/8/x48e7dp9//nl5c+jQofLm/Pnz5c0bb7xR3nzzzTflDY+fmwIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAeBBvAoZhmMimtdYOHDjQtaPPiRMnypsPP/yw66wXXnihvJmfny9vjh49Wt7w9HBTACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAgP4k3AOI4T2bTW2qZNm8qbTz75pLw5cuRIefP111+XN6219sMPP5Q3b775Znmzc+fO8ubjjz8uby5fvlzetNbad999V95s2bKl6yxWLzcFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBjG3pfXeGizs7Plzfz8fNdZzzzzTHnT8ytw9erV8ub69evlTWutbd++vWs3CT/++GN5s27duq6zXnnlla4dVLgpABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABBeSZ2AmzdvljdXrlzpOmvr1q1du6phGMqbSf6q3bp1q7y5ceNGebNt27byBlYyNwUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGA8CDeCrV58+au3XvvvVfenD59uryZ5IN43377bXkzPT1d3mzYsKG8gaeNmwIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAeBAPgHBTACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYD4B5UcSYOH6AapAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -238.2384,  -660.0082, -1059.8765,    -3.2868, -1222.2327,   338.6720,\n",
      "          -320.7259,  -704.8042,  -282.9259,  -455.4705],\n",
      "        [  314.0291,  -861.6416,  -349.7124,  -758.2955,  -293.3600,  -160.5501,\n",
      "            27.7502,  -384.7800,  -314.4612,  -328.2208]], device='mps:0')\n",
      "torch.Size([2, 10])\n",
      "Predicted: tensor([5, 0], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "test= x_train[:2]#.unsqueeze(0)\n",
    "print(test.shape)\n",
    "\n",
    "grid = utils.make_grid(test, nrow=2)\n",
    "plt.gca().set_axis_off()\n",
    "plt.imshow(transforms.functional.to_pil_image(grid), cmap=\"gray\")\n",
    "plt.show()    \n",
    "\n",
    "classifier.eval()\n",
    "with torch.no_grad():\n",
    "    t = torch.tensor([0]).to(device)\n",
    "    output = classifier(test, t)\n",
    "    print(output)\n",
    "    print(output.shape)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    print(f\"Predicted: {predicted}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2bffd3855f5744f588d5be1e5c4aed3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3b61ee9c62994863b718c086d4182f44": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "645d91e4bb974b1196be61b5077c9dc5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_78dc714c7aa347fb9fc41abf420222d9",
       "IPY_MODEL_c1260f271df547fbb2a158ff6b3a3ff4",
       "IPY_MODEL_e7313fdbb70442f4867644dfc85c3bcc"
      ],
      "layout": "IPY_MODEL_a501588b5eb0494996dfb136565365ca"
     }
    },
    "78dc714c7aa347fb9fc41abf420222d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_89c68eded05d441daf94d145addb5ece",
      "placeholder": "​",
      "style": "IPY_MODEL_2bffd3855f5744f588d5be1e5c4aed3e",
      "value": "Training:  24%"
     }
    },
    "89c68eded05d441daf94d145addb5ece": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b905c5b2ad846ca837bd20cce2bf094": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a501588b5eb0494996dfb136565365ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aca161ff9f4b4a20b1457a8ee864f150": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b1416c32c4af4fe9a3c3fdcc5f33aca0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1260f271df547fbb2a158ff6b3a3ff4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b61ee9c62994863b718c086d4182f44",
      "max": 5900,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8b905c5b2ad846ca837bd20cce2bf094",
      "value": 1394
     }
    },
    "e7313fdbb70442f4867644dfc85c3bcc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1416c32c4af4fe9a3c3fdcc5f33aca0",
      "placeholder": "​",
      "style": "IPY_MODEL_aca161ff9f4b4a20b1457a8ee864f150",
      "value": " 1393/5900 [05:15&lt;16:04,  4.67it/s, epoch=12/50, loss=⠀   2400.1270]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
